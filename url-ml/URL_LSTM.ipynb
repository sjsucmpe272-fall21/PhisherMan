{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126077"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model, Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Embedding, Dense, Flatten, Bidirectional, Dense, Dropout, Activation, BatchNormalization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import the dataset\n",
    "df = pd.read_csv('D3_data.csv', header=None)\n",
    "df.columns =['Index', 'Url', 'Result']\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = {}\n",
    "for index, row in df.iterrows():\n",
    "    urls[row['Url']] = row['Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "labels = []\n",
    "for k, v in urls.items():\n",
    "    samples.append(k)\n",
    "    labels.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 67 unique tokens.\n",
      "Shape of data tensor: (125846, 128)\n",
      "Shape of label tensor: (125846,)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data for training.\n",
    "max_chars = 20000\n",
    "maxlen = 128\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_chars, char_level=True)\n",
    "tokenizer.fit_on_texts(samples)\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "labels = np.asarray(labels)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119553 6292\n"
     ]
    }
   ],
   "source": [
    "# Divide data between training, cross-validation, and test data.\n",
    "training_samples = int(len(samples) * 0.95)\n",
    "validation_samples = int(len(labels) * 0.05)\n",
    "print(training_samples, validation_samples)\n",
    "\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "x = data[:training_samples]\n",
    "y = labels[:training_samples]\n",
    "x_test = data[training_samples: training_samples + validation_samples]\n",
    "y_test = labels[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks for Keras.\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    filepath='url_lstm.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    min_delta=0,\n",
    "    patience=2, \n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    )\n",
    "]\n",
    "\n",
    "num_chars = len(tokenizer.word_index)+1\n",
    "\n",
    "embedding_vector_length = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 128, 128)          8704      \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128, 512)          788480    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128, 512)          1574912   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 256)               656384    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,028,737\n",
      "Trainable params: 3,028,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model for training.\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_chars, embedding_vector_length, input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(256, dropout=0.3, recurrent_dropout=0.3, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(256, dropout=0.3, recurrent_dropout=0.3, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(128, dropout=0.3, recurrent_dropout=0.3)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train.\n",
    "model.fit(x, y,\n",
    "        epochs=10,\n",
    "        batch_size=1200,\n",
    "        callbacks=callbacks_list,\n",
    "        validation_split=0.20,\n",
    "        shuffle=True\n",
    "        )\n",
    "\n",
    "# Evaluate model on test data.\n",
    "score, acc = model.evaluate(x_test, y_test, verbose=1, batch_size=1024)\n",
    "\n",
    "print(\"Model Accuracy: {:0.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 8s 1s/step - loss: 0.2007 - accuracy: 0.9272\n",
      "Model Accuracy: 92.72%\n"
     ]
    }
   ],
   "source": [
    "model = load_model('url_lstm.h5')\n",
    "\n",
    "# Evaluate model on test data.\n",
    "score, acc = model.evaluate(x_test, y_test, verbose=1, batch_size=1024)\n",
    "\n",
    "print(\"Model Accuracy: {:0.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
